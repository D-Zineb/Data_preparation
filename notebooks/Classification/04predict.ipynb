{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/Classification/processed/2_preprocessed_df.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0027419...</td>\n",
       "      <td>[[[189, 152, 194], [192, 156, 198], [191, 154,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0025030...</td>\n",
       "      <td>[[[24, 13, 22], [24, 14, 22], [24, 14, 26], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0026769...</td>\n",
       "      <td>[[[186, 127, 135], [189, 133, 145], [192, 135,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0025661...</td>\n",
       "      <td>[[[24, 11, 17], [24, 11, 20], [30, 15, 25], [4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0031633...</td>\n",
       "      <td>[[[131, 88, 110], [142, 97, 120], [152, 107, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0033084...</td>\n",
       "      <td>[[[143, 125, 134], [140, 122, 131], [140, 122,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0033550...</td>\n",
       "      <td>[[[5, 6, 3], [6, 7, 4], [7, 8, 5], [8, 8, 6], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0033536...</td>\n",
       "      <td>[[[109, 99, 102], [122, 111, 112], [132, 121, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>HAM_0000239</td>\n",
       "      <td>ISIC_0032854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0032854...</td>\n",
       "      <td>[[[157, 121, 143], [160, 125, 145], [155, 114,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../../data/Classification/raw\\all\\ISIC_0032258...</td>\n",
       "      <td>[[[179, 147, 132], [177, 146, 137], [177, 141,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10015 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lesion_id      image_id   dx  dx_type   age  sex  localization  \\\n",
       "0      HAM_0000118  ISIC_0027419  2.0      3.0  80.0  0.0           9.0   \n",
       "1      HAM_0000118  ISIC_0025030  2.0      3.0  80.0  0.0           9.0   \n",
       "2      HAM_0002730  ISIC_0026769  2.0      3.0  80.0  0.0           9.0   \n",
       "3      HAM_0002730  ISIC_0025661  2.0      3.0  80.0  0.0           9.0   \n",
       "4      HAM_0001466  ISIC_0031633  2.0      3.0  75.0  0.0          11.0   \n",
       "...            ...           ...  ...      ...   ...  ...           ...   \n",
       "10010  HAM_0002867  ISIC_0033084  0.0      3.0  40.0  0.0           4.0   \n",
       "10011  HAM_0002867  ISIC_0033550  0.0      3.0  40.0  0.0           4.0   \n",
       "10012  HAM_0002867  ISIC_0033536  0.0      3.0  40.0  0.0           4.0   \n",
       "10013  HAM_0000239  ISIC_0032854  0.0      3.0  80.0  0.0           5.0   \n",
       "10014  HAM_0003521  ISIC_0032258  4.0      3.0  70.0  1.0           0.0   \n",
       "\n",
       "                                                    path  \\\n",
       "0      ../../data/Classification/raw\\all\\ISIC_0027419...   \n",
       "1      ../../data/Classification/raw\\all\\ISIC_0025030...   \n",
       "2      ../../data/Classification/raw\\all\\ISIC_0026769...   \n",
       "3      ../../data/Classification/raw\\all\\ISIC_0025661...   \n",
       "4      ../../data/Classification/raw\\all\\ISIC_0031633...   \n",
       "...                                                  ...   \n",
       "10010  ../../data/Classification/raw\\all\\ISIC_0033084...   \n",
       "10011  ../../data/Classification/raw\\all\\ISIC_0033550...   \n",
       "10012  ../../data/Classification/raw\\all\\ISIC_0033536...   \n",
       "10013  ../../data/Classification/raw\\all\\ISIC_0032854...   \n",
       "10014  ../../data/Classification/raw\\all\\ISIC_0032258...   \n",
       "\n",
       "                                                   image  \n",
       "0      [[[189, 152, 194], [192, 156, 198], [191, 154,...  \n",
       "1      [[[24, 13, 22], [24, 14, 22], [24, 14, 26], [2...  \n",
       "2      [[[186, 127, 135], [189, 133, 145], [192, 135,...  \n",
       "3      [[[24, 11, 17], [24, 11, 20], [30, 15, 25], [4...  \n",
       "4      [[[131, 88, 110], [142, 97, 120], [152, 107, 1...  \n",
       "...                                                  ...  \n",
       "10010  [[[143, 125, 134], [140, 122, 131], [140, 122,...  \n",
       "10011  [[[5, 6, 3], [6, 7, 4], [7, 8, 5], [8, 8, 6], ...  \n",
       "10012  [[[109, 99, 102], [122, 111, 112], [132, 121, ...  \n",
       "10013  [[[157, 121, 143], [160, 125, 145], [155, 114,...  \n",
       "10014  [[[179, 147, 132], [177, 146, 137], [177, 141,...  \n",
       "\n",
       "[10015 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df.drop(columns=['dx'],axis=1)\n",
    "target=df['dx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.25,random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train_o['image'].tolist())\n",
    "x_test = np.asarray(x_test_o['image'].tolist())\n",
    "\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean)/x_train_std\n",
    "x_test = (x_test - x_test_mean)/x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform one-hot encoding on the labels\n",
    "y_train = to_categorical(y_train_o, num_classes = 7)\n",
    "y_test = to_categorical(y_test_o, num_classes = 7)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 999)\n",
    "x_train = x_train.reshape(x_train.shape[0], *(100, 125, 3))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(100, 125, 3))\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *(100, 125, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6759, 100, 125, 3)\n",
      "(2504, 100, 125, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6759, 37500)\n",
      "(2504, 37500)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(6759,125*100*3)\n",
    "x_test = x_test.reshape(2504,125*100*3)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "676/676 [==============================] - 15s 12ms/step - loss: 0.9894 - accuracy: 0.6707\n",
      "Epoch 2/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.8976 - accuracy: 0.6880\n",
      "Epoch 3/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.8502 - accuracy: 0.7022\n",
      "Epoch 4/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.8213 - accuracy: 0.7119\n",
      "Epoch 5/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.7858 - accuracy: 0.7196\n",
      "Epoch 6/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.7605 - accuracy: 0.7273\n",
      "Epoch 7/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.7279 - accuracy: 0.7381\n",
      "Epoch 8/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.7028 - accuracy: 0.7463\n",
      "Epoch 9/50\n",
      "676/676 [==============================] - 8s 13ms/step - loss: 0.6781 - accuracy: 0.7514\n",
      "Epoch 10/50\n",
      "676/676 [==============================] - 8s 13ms/step - loss: 0.6574 - accuracy: 0.7628\n",
      "Epoch 11/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.6419 - accuracy: 0.7655\n",
      "Epoch 12/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.6207 - accuracy: 0.7775\n",
      "Epoch 13/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.5996 - accuracy: 0.7835\n",
      "Epoch 14/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.5722 - accuracy: 0.7911\n",
      "Epoch 15/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.5635 - accuracy: 0.7983\n",
      "Epoch 16/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.5403 - accuracy: 0.8074\n",
      "Epoch 17/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.5300 - accuracy: 0.8124\n",
      "Epoch 18/50\n",
      "676/676 [==============================] - 9s 13ms/step - loss: 0.4944 - accuracy: 0.8194\n",
      "Epoch 19/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.4943 - accuracy: 0.8241\n",
      "Epoch 20/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.4629 - accuracy: 0.8319\n",
      "Epoch 21/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.4605 - accuracy: 0.8337\n",
      "Epoch 22/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.4458 - accuracy: 0.8396\n",
      "Epoch 23/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.4197 - accuracy: 0.8489\n",
      "Epoch 24/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.4334 - accuracy: 0.8423\n",
      "Epoch 25/50\n",
      "676/676 [==============================] - 8s 13ms/step - loss: 0.3957 - accuracy: 0.8578\n",
      "Epoch 26/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3938 - accuracy: 0.8560\n",
      "Epoch 27/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3911 - accuracy: 0.8612\n",
      "Epoch 28/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3691 - accuracy: 0.8701\n",
      "Epoch 29/50\n",
      "676/676 [==============================] - 9s 13ms/step - loss: 0.3599 - accuracy: 0.8720\n",
      "Epoch 30/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3477 - accuracy: 0.8735\n",
      "Epoch 31/50\n",
      "676/676 [==============================] - 9s 13ms/step - loss: 0.3309 - accuracy: 0.8819\n",
      "Epoch 32/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3293 - accuracy: 0.8809\n",
      "Epoch 33/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3183 - accuracy: 0.8895\n",
      "Epoch 34/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3158 - accuracy: 0.8862\n",
      "Epoch 35/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3005 - accuracy: 0.8896\n",
      "Epoch 36/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.3142 - accuracy: 0.8883\n",
      "Epoch 37/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2982 - accuracy: 0.8936\n",
      "Epoch 38/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2666 - accuracy: 0.9041\n",
      "Epoch 39/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2752 - accuracy: 0.9038\n",
      "Epoch 40/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2850 - accuracy: 0.9013\n",
      "Epoch 41/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2795 - accuracy: 0.9018\n",
      "Epoch 42/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2413 - accuracy: 0.9163\n",
      "Epoch 43/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2509 - accuracy: 0.9133\n",
      "Epoch 44/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2434 - accuracy: 0.9160\n",
      "Epoch 45/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2467 - accuracy: 0.9169\n",
      "Epoch 46/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2277 - accuracy: 0.9197\n",
      "Epoch 47/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2322 - accuracy: 0.9216\n",
      "Epoch 48/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2483 - accuracy: 0.9136\n",
      "Epoch 49/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2220 - accuracy: 0.9231\n",
      "Epoch 50/50\n",
      "676/676 [==============================] - 8s 12ms/step - loss: 0.2017 - accuracy: 0.9281\n",
      "79/79 [==============================] - 3s 4ms/step - loss: 1.6164 - accuracy: 0.7113\n",
      "Test: accuracy =  71.12619876861572 %\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units= 64, kernel_initializer = 'uniform', activation = 'relu', input_dim = 37500))\n",
    "model.add(Dense(units= 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(units= 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(units= 64, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00075,\n",
    "                                    beta_1 = 0.9,\n",
    "                                    beta_2 = 0.999,\n",
    "                                    epsilon = 1e-8)\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "history = model.fit(x_train, y_train, batch_size = 10, epochs = 50)\n",
    "\n",
    "accuracy = model.evaluate(x_test, y_test, verbose=1)[1]\n",
    "print(\"Test: accuracy = \",accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['lesion_id','image_id','path','image','dx'],axis=1)\n",
    "y = df['dx']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear') \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.01%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (metrics.accuracy_score(y_test, y_pred) * 100.0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
